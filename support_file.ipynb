{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e833df01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-api-python-client\n",
    "# !pip install google-auth\n",
    "# !pip install google-auth-oauthlib\n",
    "# !pip install google-auth-httplib2\n",
    "# !pip install youtube-transcript-api\n",
    "# !pip install moviepy librosa\n",
    "# !pip install pytube\n",
    "# !pip install --upgrade librosa\n",
    "# !pip install opencv-python\n",
    "# !pip install --upgrade numpy\n",
    "# !pip install isodate\n",
    "# !pip install moviepy\n",
    "# !pip install googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc48de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.auth\n",
    "from googleapiclient.discovery import build\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import openai, base64, os, time, json, sys\n",
    "from pytube import YouTube\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip, AudioFileClip\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "from isodate import parse_duration\n",
    "from pydub import AudioSegment\n",
    "import speech_recognition as sr\n",
    "from wrapt_timeout_decorator import timeout\n",
    "from gtts import gTTS\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea1f178",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"./secret_keys.json\"\n",
    "\n",
    "# Loads the .json file generated from extracting metadata for a given channel ID\n",
    "with open(path, 'r') as file:\n",
    "    secret_keys = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b395e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_api = secret_keys['youtube_api']\n",
    "openai_api = secret_keys['openai_api']\n",
    "google_custom_search_apikey = secret_keys['google_custom_search_apikey']\n",
    "search_engine_id = secret_keys['search_engine_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e34f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "\n",
    "#Functions to extract youtube vidoe content, subtitles and even download videos as well.\n",
    "def get_video_details(channel_id):\n",
    "    # Set up YouTube API service\n",
    "    youtube = build('youtube', 'v3', developerKey=youtube_api)\n",
    "    \n",
    "    # Get the playlist ID of the uploads playlist for the channel\n",
    "    response = youtube.channels().list(part=\"contentDetails\", id=channel_id).execute()\n",
    "    playlist_id = response[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n",
    "\n",
    "    # Get the video details from the uploads playlist\n",
    "    videos = []\n",
    "    next_page_token = None\n",
    "    limit = 50\n",
    "    while True:\n",
    "        playlist_items = youtube.playlistItems().list(\n",
    "            part=\"snippet\",\n",
    "            playlistId=playlist_id,\n",
    "            maxResults=limit,\n",
    "            pageToken=next_page_token,\n",
    "        ).execute()\n",
    "\n",
    "        videos.extend(playlist_items[\"items\"])\n",
    "        next_page_token = playlist_items.get(\"nextPageToken\")\n",
    "\n",
    "        if (not next_page_token) | (len(videos) >= limit):\n",
    "            break\n",
    "    return videos\n",
    "\n",
    "def get_youtube_video_info(api_key, video_id):\n",
    "    '''This function extracts the details of a youtube video using its video ID'''\n",
    "    \n",
    "    # Set up YouTube API service\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "    # Get video details\n",
    "    request = youtube.videos().list(part='snippet,contentDetails,statistics', id=video_id)\n",
    "    response = request.execute()\n",
    "\n",
    "    if 'items' in response:\n",
    "        video_info = response['items'][0]\n",
    "        return video_info\n",
    "    else:\n",
    "        print(\"Video not found.\")\n",
    "                \n",
    "def search_videos(api_key, query, max_results=5):\n",
    "    '''This function extracts the details a list of youtube videos given certain keywords.'''\n",
    "    \n",
    "    # Set up YouTube API service\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "    # Search for videos based on keywords\n",
    "    request = youtube.search().list(\n",
    "        part='snippet',\n",
    "        q=query,\n",
    "        type='video',\n",
    "        maxResults=max_results)\n",
    "\n",
    "    response = request.execute()\n",
    "\n",
    "    if 'items' in response:\n",
    "        videos = response['items']\n",
    "        return videos\n",
    "    else:\n",
    "        print(\"No videos found.\")\n",
    "        \n",
    "def convert_duration_to_seconds(duration):\n",
    "    # Parse the ISO 8601 duration format\n",
    "    duration_obj = parse_duration(duration)\n",
    "\n",
    "    # Calculate the total duration in seconds\n",
    "    total_seconds = duration_obj.total_seconds()\n",
    "\n",
    "    return int(total_seconds)\n",
    "    \n",
    "def get_video_transcript(video_id, languages):\n",
    "    '''This function extracts the subtitle of a youtube video using its video ID'''\n",
    "\n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi.get_transcripts(video_id, languages=languages)\n",
    "        return transcript\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_transcript_to_file(transcript, output_file):\n",
    "    '''This functions saves the subtitle extracted from the chosen video.'''\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        for entry in transcript:\n",
    "            file.write(f\"{entry['start']} - {entry['start'] + entry['duration']}\\n\")\n",
    "            file.write(f\"{entry['text']}\\n\\n\")\n",
    "\n",
    "def combine_transcript(transcript):\n",
    "    '''This processes the extracted subtitle and combines all its texts into one long string.'''\n",
    "    string = ''\n",
    "    for subt in transcript:\n",
    "        string = string+f\" {subt['text']}\"\n",
    "    return string\n",
    "\n",
    "def download_youtube_video(video_url, output_path='.'):\n",
    "    '''This function downloads a given youtube video using its video url.'''\n",
    "    try:\n",
    "        # Create a YouTube object\n",
    "        yt = YouTube(video_url)\n",
    "\n",
    "        # Get the highest resolution stream\n",
    "        video_stream = yt.streams.get_highest_resolution()\n",
    "\n",
    "        # Download the video\n",
    "        video_stream.download(output_path)\n",
    "        print(f\"Video downloaded successfully to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        \n",
    "def download_and_analyze_audio(video_id, output_path='audio_files'):\n",
    "    '''This fucntion downloads the video audio file using the video ID and calculated the\n",
    "    audio BPM (Beats per minute).'''\n",
    "\n",
    "    try:\n",
    "        # Construct the YouTube video URL\n",
    "        video_url = f'https://www.youtube.com/watch?v={video_id}'\n",
    "\n",
    "        # Create a YouTube object\n",
    "        yt = YouTube(video_url)\n",
    "\n",
    "        # Get the highest quality audio stream\n",
    "        audio_stream = yt.streams.filter(only_audio=True, file_extension='mp4').first()\n",
    "\n",
    "        # Set the output path (default: 'downloads')\n",
    "        audio_stream.download(output_path)\n",
    "\n",
    "        #print(f\"Audio downloaded successfully to: {output_path}/{yt.title}.mp4\")\n",
    "\n",
    "        # Get the downloaded audio file path\n",
    "        downloaded_audio_path = f\"{output_path}/{yt.title}.mp4\"\n",
    "\n",
    "        # Convert the downloaded audio to MP3\n",
    "        audio_clip = AudioFileClip(downloaded_audio_path)\n",
    "        audio_clip.write_audiofile(f\"{output_path}/{yt.title}.mp3\")\n",
    "\n",
    "        #print(f\"Audio downloaded and converted to MP3 successfully.\")\n",
    "\n",
    "        y, sr = librosa.load(f\"{output_path}/{yt.title}.mp3\") #Loads the extracted and stored audio\n",
    "\n",
    "        # Compute the tempo\n",
    "        tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "        tempo = round(tempo)\n",
    "\n",
    "        # Deletes the .mp4 and .mp3 file after use to ease up space\n",
    "        os.remove(f\"{output_path}/{yt.title}.mp4\")\n",
    "        os.remove(f\"{output_path}/{yt.title}.mp3\")\n",
    "        #print(f'Tempo: {tempo} BPM')\n",
    "        return tempo\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "#Functions for executing text analysis and processor (classification, summarization, topic modelling).\n",
    "def gpt_punctuator(information):\n",
    "    '''Function is responsible for querying the GPT-3.5 model for analysis of a given content.'''\n",
    "    import openai\n",
    "\n",
    "    #Prompt engineering message to be fed to the GPT model.\n",
    "    messages = [\n",
    "        {\"role\":\"system\",\"content\":\"you are a text analyst assistant. Your job is to punctuate a given text and output only the resulting punctuated text without omiting a single word.\"}]\n",
    "    \n",
    "    openai_obj = openai\n",
    "    openai_obj.api_key = openai_api\n",
    "\n",
    "    #Creates the prompt to check for the most similar column\n",
    "    prompt_1 = f\"{information}\"\n",
    "    prompt_2 = \"Please properly punctuate the given text (without omitting a single word) and output only the resulting punctuated text. Please do not omit a single word from the original text.\"\n",
    "\n",
    "    #Adds the prompts to the chat memory\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt_1},)\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt_2},)\n",
    "\n",
    "    #GPT model is triggered and response is generated.\n",
    "    chat = openai_obj.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages, \n",
    "        temperature=0.0,\n",
    "        timeout=5\n",
    "    ) \n",
    "\n",
    "    #Response is extracted\n",
    "    response = chat.choices[0].message.content\n",
    "    return (response)\n",
    "\n",
    "def gpt_categorizer(information):\n",
    "    '''Function is responsible for querying the GPT-3.5 model for analysis of a given content.'''\n",
    "    import openai\n",
    "\n",
    "    #Prompt engineering message to be fed to the GPT model.\n",
    "    messages = [\n",
    "        {\"role\":\"system\",\"content\":\"you are a text analyst assistant. Given a text to analyze, you're to only respond with 'Basic','Medium', or 'Advanced'.\"}]\n",
    "    \n",
    "    openai_obj = openai\n",
    "    openai_obj.api_key = openai_api\n",
    "\n",
    "    #Creates the prompt to check for the most similar column\n",
    "    prompt_1 = f\"{information}\"\n",
    "    prompt_2 = \"Given the text which is a transcript of a language tutorial video, which category of difficulty (Basic, Medium and Advanced) best describes what is being taught? Output only the category and nothing else.\"\n",
    "\n",
    "    #Adds the prompts to the chat memory\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt_1},)\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt_2},)\n",
    "\n",
    "    #GPT model is triggered and response is generated.\n",
    "    chat = openai_obj.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages, \n",
    "        temperature=0.0,\n",
    "        timeout=5\n",
    "    ) \n",
    "\n",
    "    #Response is extracted\n",
    "    response = chat.choices[0].message.content\n",
    "    return (response)\n",
    "\n",
    "def gpt_summarizer(information):\n",
    "    '''Function is responsible for querying the GPT-3.5 model for analysis of a given content.'''\n",
    "    import openai\n",
    "\n",
    "    #Prompt engineering message to be fed to the GPT model.\n",
    "    messages = [\n",
    "        {\"role\":\"system\",\"content\":\"you are a text analyst assistant. Given a text to analyze, you're to summarize the content in a few sentences.\"}]\n",
    "    \n",
    "    openai_obj = openai\n",
    "    openai_obj.api_key = openai_api\n",
    "\n",
    "    #Creates the prompt to check for the most similar column\n",
    "    prompt_1 = f\"{information}\"\n",
    "    prompt_2 = \"Given the text which is a transcript of a language tutorial video, please summarize the content in 5 to 10 sentences.\"\n",
    "\n",
    "    #Adds the prompts to the chat memory\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt_1},)\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt_2},)\n",
    "\n",
    "    #GPT model is triggered and response is generated.\n",
    "    chat = openai_obj.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages, \n",
    "        temperature=0.0,\n",
    "        timeout=5\n",
    "    ) \n",
    "\n",
    "    #Response is extracted\n",
    "    response = chat.choices[0].message.content\n",
    "    return (response)\n",
    "\n",
    "def gpt_topicmodeller(information):\n",
    "    '''Function is responsible for querying the GPT-3.5 model for analysis of a given content.'''\n",
    "    import openai\n",
    "\n",
    "    #Prompt engineering message to be fed to the GPT model.\n",
    "    messages = [\n",
    "        {\"role\":\"system\",\"content\":\"you are a text analyst assistant. Given a text to analyze, you're to generate a single topic that best represent the contents within.\"}]\n",
    "    \n",
    "    openai_obj = openai\n",
    "    openai_obj.api_key = openai_api\n",
    "\n",
    "    #Creates the prompt to check for the most similar column\n",
    "    prompt_1 = f\"{information}\"\n",
    "    prompt_2 = \"Given the text which is a transcript of a language tutorial video, please generate a single topic that describes the content being taught. Output only this topic.\"\n",
    "\n",
    "    #Adds the prompts to the chat memory\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt_1},)\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt_2},)\n",
    "\n",
    "    #GPT model is triggered and response is generated.\n",
    "    chat = openai_obj.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages, \n",
    "        temperature=0.0,\n",
    "        timeout=5\n",
    "    ) \n",
    "\n",
    "    #Response is extracted\n",
    "    response = chat.choices[0].message.content\n",
    "    return (response)\n",
    "\n",
    "def gpt_qualitycheck(information):\n",
    "    '''Function is responsible for querying the GPT-3.5 model for analysis of a given content.'''\n",
    "    import openai\n",
    "\n",
    "    #Prompt engineering message to be fed to the GPT model.\n",
    "    messages = [\n",
    "        {\"role\":\"system\",\"content\":\"you are a text analyst assistant. Given a text to analyze, you're to respond with only 'Poorly articulated','Moderately articulated' or 'Very articulated'.\"}]\n",
    "    \n",
    "    openai_obj = openai\n",
    "    openai_obj.api_key = openai_api\n",
    "\n",
    "    #Creates the prompt to check for the most similar column\n",
    "    prompt_1 = f\"{information}\"\n",
    "    prompt_2 = \"Given the text which is a transcript of a language tutorial video, is the content 'Poorly articulated', 'Moderately articulated', or 'Very articulated'? Output only the category and nothing else.\"\n",
    "\n",
    "    #Adds the prompts to the chat memory\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt_1},)\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt_2},)\n",
    "\n",
    "    #GPT model is triggered and response is generated.\n",
    "    chat = openai_obj.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages, \n",
    "        temperature=0.0,\n",
    "        timeout=5\n",
    "    ) \n",
    "\n",
    "    #Response is extracted\n",
    "    response = chat.choices[0].message.content\n",
    "    return (response)\n",
    "\n",
    "\n",
    "#Functions for extracting the audio from the downloaded video and analyzing this audio.        \n",
    "def extract_audio(video_path, audio_path):\n",
    "    '''This function extracts the audio file from the downloaded youtube video.'''\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "    audio_clip = video_clip.audio\n",
    "    audio_clip.write_audiofile(audio_path, fps=44100)  # Set the desired sample rate\n",
    "\n",
    "def analyze_audio(audio_path):\n",
    "    '''This function analyses the extracted audio.'''\n",
    "    y, sr = librosa.load(audio_path)\n",
    "\n",
    "    # Example: Display the waveform\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    librosa.display.waveshow(y=y, sr=sr)\n",
    "    plt.title('Waveform')\n",
    "    plt.show()\n",
    "\n",
    "    # Example: Display the spectrogram\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Spectrogram')\n",
    "    plt.show()\n",
    "    \n",
    "def analyze_audio_speed(audio_path):\n",
    "    '''This function analyses the speed of the audio file.'''\n",
    "    y, sr = librosa.load(audio_path)\n",
    "\n",
    "    # Compute the tempo\n",
    "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "\n",
    "    print(f'Tempo: {tempo} BPM')\n",
    "\n",
    "    # Example: Display the waveform\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    librosa.display.waveshow(y, sr=sr)\n",
    "    plt.title('Waveform')\n",
    "    plt.show()\n",
    "   \n",
    "   \n",
    "#Functions to analyze the image frames extracted from the downloaded video\n",
    "def list_files_in_folder(folder_path):\n",
    "    '''This function add the names of the image frames extracted from the downloaded video to a list.'''\n",
    "    list_of_contents = []\n",
    "    try:\n",
    "        # Get the list of files and directories in the specified folder\n",
    "        contents = os.listdir(folder_path)\n",
    "\n",
    "        # Print the list of contents\n",
    "        print(f\"Contents of {folder_path}:\")\n",
    "        for entry in contents:\n",
    "            list_of_contents.append(str(entry))\n",
    "            print(entry)\n",
    "        return list_of_contents\n",
    "    except FileNotFoundError:\n",
    "        print(f\"The folder '{folder_path}' does not exist.\")\n",
    "    except PermissionError:\n",
    "        print(f\"Permission denied to access '{folder_path}'.\")\n",
    "        \n",
    "        \n",
    "def gpt_V_image_analyser(image_name):\n",
    "    '''This function converts the extracted image frames to base64 and analyzes its content using GPT4-V'''\n",
    "    # Updated file path to a JPEG image\n",
    "    image_path_base = r\".\\output_frames\\\\\"\n",
    "    \n",
    "    image_path = image_path_base + image_name\n",
    "\n",
    "    # Read and encode the image in base64\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "    # Craft the prompt for GPT\n",
    "    prompt_messages = [{\"role\": \"user\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": \"Does this image contain any infographics? Reply with only 'Yes' or 'No' and no added punctuations.\"},\n",
    "                                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encoded_image}\"}}]\n",
    "                   }]\n",
    "\n",
    "    # Send a request to GPT\n",
    "    params = {\n",
    "        \"model\": \"gpt-4-vision-preview\",\n",
    "        \"messages\": prompt_messages,\n",
    "        \"api_key\": openai_api,\n",
    "        # \"response_format\": {\"type\": \"json_object\"},  # Added response format\n",
    "        \"headers\": {\"Openai-Version\": \"2020-11-07\"},\n",
    "        \"max_tokens\": 4096,\n",
    "    }\n",
    "\n",
    "    result = openai.ChatCompletion.create(**params)\n",
    "    print(result.choices[0].message.content)\n",
    "    return result.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d059d3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4352384",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Extract video details using its video ID\n",
    "video_id = 'axYAW7PuSIM'\n",
    "video_info = get_youtube_video_info(youtube_api, video_id)\n",
    "video_info['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64a70dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = video_info['snippet']['defaultAudioLanguage'].split('-')[0]\n",
    "language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d6bb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Extracts the top 2 videos using a given keyword\n",
    "\n",
    "# Replace 'KEYWORDS' with the keywords you want to search for\n",
    "keywords = 'English Tutorial'\n",
    "\n",
    "# Set the maximum number of results to retrieve (default is 5)\n",
    "max_results = 2\n",
    "\n",
    "videos = search_videos(youtube_api, keywords, max_results)\n",
    "\n",
    "if videos:\n",
    "    for index in range(len(videos)):\n",
    "        overall_dictionary[f\"Video_{index}\"] = {}\n",
    "        overall_dictionary[f\"Video_{index}\"]['ID'] = videos[index]['id']['videoId']\n",
    "        overall_dictionary[f\"Video_{index}\"]['Details'] = videos[index]\n",
    "        \n",
    "        print(\"Video Title:\", videos[index]['snippet']['title'])\n",
    "        print(\"Channel:\", videos[index]['snippet']['channelTitle'])\n",
    "        print(\"Video ID:\", videos[index]['id']['videoId'])\n",
    "        print(\"Published At:\", videos[index]['snippet']['publishedAt'])\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c49092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "video_url = \"https://www.youtube.com/watch?v=axYAW7PuSIM\"  # Replace with the actual YouTube video URL\n",
    "# video_id = [\"E4h-8rw2GlY\"]\n",
    "video_id = [\"_F6LG3TYnFQ\"]\n",
    "language_code = ['en']  # Replace with the desired language code (e.g., \"en\" for English)\n",
    "\n",
    "video_transcript = get_video_transcript(video_id, language_code)\n",
    "video_transcript = video_transcript[0][video_id[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419afce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_duration = \"PT10M32S\" \n",
    "seconds = convert_duration_to_seconds(youtube_duration)\n",
    "print(f\"Duration in seconds: {seconds} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897d1c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_duration = 0\n",
    "number_of_words = 0\n",
    "speed_categories = {'Slow Speech':[0,110],'Normal Speech':[110,150],'Fast Speech':[150,200]}\n",
    "for text in video_transcript:\n",
    "    if text['text'] != '[Music]':\n",
    "        print(combined_duration, text['duration'])\n",
    "        combined_duration += int(text['duration'])\n",
    "        print(combined_duration)\n",
    "        number_of_words += int(len(text['text'].split(' ')))\n",
    "\n",
    "words_per_minute = round(number_of_words/(combined_duration/60))\n",
    "for categ in list(speed_categories.keys()):\n",
    "    if (words_per_minute >= speed_categories[categ][0]) & (words_per_minute < speed_categories[categ][1]):\n",
    "        audio_speed = categ\n",
    "print(combined_duration, number_of_words, f\"{words_per_minute} WPM\", audio_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19fe659",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_subt = combine_transcript(video_transcript)\n",
    "combined_subt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c553f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(combined_subt.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb51d73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Extracts the subtitles of one of the extracted videos\n",
    "\n",
    "# Replace 'VIDEO_ID' with the actual YouTube video ID\n",
    "video_id = overall_dictionary[\"Video_1\"]['ID']\n",
    "\n",
    "# Replace 'output.txt' with the desired output file name\n",
    "output_file = 'output.txt'\n",
    "\n",
    "# Get video transcript\n",
    "video_transcript = get_video_transcript(video_id)\n",
    "\n",
    "if video_transcript:\n",
    "    # Save transcript to a file\n",
    "    combined_subt = combine_transcript(video_transcript)\n",
    "    overall_dictionary[\"Video_1\"]['Subtitle'] = combined_subt\n",
    "    print(f\"Retrieved transcript.\")\n",
    "else:\n",
    "    print(\"Failed to retrieve transcript.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5213798",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_subt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa075ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Preprocesses the subtitle, so that GPT can process it without trucnating it.\n",
    "split_subtitle = combined_subt.split(' ')\n",
    "print(f\"Number of words: {len(split_subtitle)}\")\n",
    "subtitle_list, punct_subt_list = [], []\n",
    "combined_words, count = '', 0\n",
    "for word in split_subtitle:\n",
    "    combined_words = combined_words + f\" {word}\"\n",
    "    count += len(word)\n",
    "    if count >= 6000:\n",
    "        subtitle_list.append(combined_words)\n",
    "        combined_words, count = '', 0\n",
    "subtitle_list.append(combined_words)\n",
    "\n",
    "for part_sub in subtitle_list:\n",
    "    print(f\"Length of text being analysed: {len(part_sub)}\")\n",
    "    combined_subt_punct = gpt_punctuator(part_sub)\n",
    "    punct_subt_list.append(combined_subt_punct)\n",
    "    \n",
    "for i in range(len(punct_subt_list)):\n",
    "    if i == 0:\n",
    "        final_combined_punct_subt = punct_subt_list[i]\n",
    "    else:\n",
    "        final_combined_punct_subt = final_combined_punct_subt + f\" {punct_subt_list[i]}\"\n",
    "overall_dictionary[\"Video_1\"]['Punctuated Subtitle'] = final_combined_punct_subt\n",
    "\n",
    "#Further preprocessing of text in subtitle so as to fit GPT's token limit.\n",
    "split_info = []\n",
    "for info in punct_subt_list:\n",
    "    split_info = split_info + info.split(' ')\n",
    "\n",
    "split_info = split_info[:3000]\n",
    "trunc_string = ''\n",
    "for i in range(len(split_info)):\n",
    "    if i == 0:\n",
    "        trunc_string = split_info[i]\n",
    "    else:\n",
    "        trunc_string = trunc_string + f\" {split_info[i]}\"\n",
    "print(len(split_info), len(trunc_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67ca5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(final_combined_punct_subt), len(combined_subt), len(trunc_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4923b40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Analyses the punctuated subtitle for meaningful insights\n",
    "category = gpt_categorizer(trunc_string)\n",
    "summary = gpt_summarizer(trunc_string)\n",
    "topic = gpt_topicmodeller(trunc_string)\n",
    "quality = gpt_qualitycheck(trunc_string)\n",
    "\n",
    "overall_dictionary[\"Video_1\"]['Category'] = category\n",
    "overall_dictionary[\"Video_1\"]['Summary'] = summary\n",
    "overall_dictionary[\"Video_1\"]['Topic'] = topic\n",
    "overall_dictionary[\"Video_1\"]['Quality'] = quality\n",
    "\n",
    "print(f'{category}\\n\\n{summary}\\n\\n{topic}\\n\\n{quality}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aed701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#overall_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cb5ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Downloads the video using the video url and saves to pwd\n",
    "\n",
    "# Replace 'VIDEO_URL' with the actual YouTube video URL\n",
    "video_url = f\"https://www.youtube.com/watch?v={overall_dictionary['Video_1']['ID']}\"\n",
    "\n",
    "# Replace '.' with the desired output directory\n",
    "output_directory = '.'\n",
    "\n",
    "download_youtube_video(video_url, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f18a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Extracts the audio file from the downloaded video\n",
    "\n",
    "# Replace 'video.mp4' with the path to your downloaded video file\n",
    "video_path = f\"{overall_dictionary['Video_1']['Details']['snippet']['title']}.mp4\"\n",
    "\n",
    "# Replace 'extracted_audio.wav' with the desired audio output path\n",
    "audio_path = 'extracted_audio.wav'\n",
    "\n",
    "extract_audio(video_path, audio_path)\n",
    "overall_dictionary[\"Video_1\"]['Audio'] = audio_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4231963",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Analyses the audio speed of the downloaded video\n",
    "audio_path = overall_dictionary[\"Video_1\"]['Audio']\n",
    "\n",
    "analyze_audio_speed(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb600ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Extracts the list of images frames from the image frames folder\n",
    "\n",
    "# Replace 'path/to/your/folder' with the path to the folder you want to list\n",
    "folder_path = '.\\output_frames'\n",
    "\n",
    "contents_list = list_files_in_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c7c8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Anlyzes the content of the extracted frames for certain contents\n",
    "#Note: in future implementation, images will be described and each description will then be fed back into GPT to decide if video is well articulated.\n",
    "\n",
    "#GPT 4V Image Analysis\n",
    "overall_dictionary[\"Video_1\"]['Video_Content_Analysis'] = []\n",
    "for image in contents_list:\n",
    "    response = gpt_V_image_analyser(image)\n",
    "    overall_dictionary[\"Video_1\"]['Video_Content_Analysis'].append(response)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745ae5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary to JSON string\n",
    "overall_response_string = json.dumps(overall_dictionary, indent=4)  # Use indent for pretty formatting\n",
    "\n",
    "# Save JSON string to a file\n",
    "with open(\"overall_response.json\", \"w\") as json_file:\n",
    "    json_file.write(overall_response_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf16c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [mp4_path, mp3_path, wav_path_1, wav_path_2, wav_path_3]\n",
    "for path in paths:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8bfc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_transcribe_audio(file_path, first_language, second_language, segment_duration_ms=4000):\n",
    "    \n",
    "    language_isocode = {'english':'en-US', 'italian':'it-IT', 'french':'fr-FR'}\n",
    "    language_list = []\n",
    "    for language in [first_language.lower(), second_language.lower()]:\n",
    "        language_list.append(language_isocode[language])\n",
    "    print(language_list)\n",
    "                              \n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    # Load the entire audio file\n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "\n",
    "    # Calculate the number of segments\n",
    "    num_segments = len(audio) // segment_duration_ms + 1\n",
    "    print(num_segments)\n",
    "    count_1, count_2, count_3, count_4 = 0, 0, 0, 0\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        \n",
    "        count_4 += 1\n",
    "        # Calculate start and end time for each segment\n",
    "        start_time = i * segment_duration_ms\n",
    "        end_time = (i + 1) * segment_duration_ms\n",
    "\n",
    "        # Extract the segment\n",
    "        segment = audio[start_time:end_time]\n",
    "\n",
    "        # Save the segment to a temporary file\n",
    "        temp_file_path = f\"audio_files/temp_segment_{i}.wav\"\n",
    "        segment.export(temp_file_path, format=\"wav\")\n",
    "\n",
    "        try:\n",
    "            # Transcribe the segment while trying the first language\n",
    "            with sr.AudioFile(temp_file_path) as audio_file:\n",
    "                audio_data = recognizer.record(audio_file)\n",
    "                text = recognizer.recognize_google(audio_data, language=language_list[0])\n",
    "                print(f\"Segment {i + 1} Transcription:\", text)\n",
    "                count_3 += 1\n",
    "                count_2 += 1\n",
    "        except sr.UnknownValueError:\n",
    "            try:\n",
    "                # Transcribe the segment while trying the second language\n",
    "                with sr.AudioFile(temp_file_path) as audio_file:\n",
    "                    audio_data = recognizer.record(audio_file)\n",
    "                    text = recognizer.recognize_google(audio_data, language=language_list[1])\n",
    "                    print(f\"Segment {i + 1} Transcription:\", text)\n",
    "                    count_3 += 1\n",
    "                    count_1 += 1\n",
    "            except sr.UnknownValueError:\n",
    "                print(f\"Segment {i + 1} - Speech Recognition could not understand audio\")\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Segment {i + 1} - Could not request results from Google Speech Recognition service; {e}\")\n",
    "        os.remove(temp_file_path)\n",
    "    \n",
    "    percentage_transcribed = round((count_3/count_4)*100)\n",
    "    percentage_english = round((count_2/count_3)*100)\n",
    "    percentage_italian = 100-percentage_english\n",
    "    print(f\"Percentage transcribed: {percentage_transcribed}%, en: {percentage_english}%, it: {percentage_italian}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea46119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "audio_file_path = \"path/to/your/multilingual_audio.wav\"  # Replace with the actual file path\n",
    "# Specify language segments and their durations in seconds\n",
    "language_segments = [(\"en-US\"), (\"fr-FR\")]\n",
    "\n",
    "transcribe_multilingual_audio(audio_file_path, language_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5ee4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Example usage:\n",
    "audio_file_path = wav_path_1  # Replace with the actual file path\n",
    "split_and_transcribe_audio(audio_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a492952",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Example usage:\n",
    "audio_file_path = wav_path_2  # Replace with the actual file path\n",
    "split_and_transcribe_audio(audio_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f37254",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Example usage:\n",
    "audio_file_path = wav_path_3  # Replace with the actual file path\n",
    "split_and_transcribe_audio(audio_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022d96ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_path_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f17a331",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Example usage:\n",
    "audio_file_path = 'audio_files/Italian Conversation Practice for Beginners  Learn Italian_3.wav'  # Replace with the actual file path\n",
    "split_and_transcribe_audio(audio_file_path, 'English', 'Italian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5f6846",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Example usage:\n",
    "audio_file_path = 'audio_files/Learn French with TINTIN 1 (fr sub)_2.wav'  # Replace with the actual file path\n",
    "split_and_transcribe_audio(audio_file_path, 'French', 'English')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab43781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(text, source_language):\n",
    "    translator = Translator()\n",
    "\n",
    "    # Translate the text to English\n",
    "    translated_text = translator.translate(text, src=source_language, dest='en')\n",
    "\n",
    "    return translated_text.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaf783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'your_text' with the text you want to translate\n",
    "text_to_translate = \"c'est Lille c'est une île et noir\"\n",
    "\n",
    "# Replace 'es' with the language code of the source text\n",
    "source_language_code = 'fr'  # 'es' is the language code for Spanish\n",
    "\n",
    "translated_text = translate_text(text_to_translate, source_language_code)\n",
    "print(f\"Original text: {text_to_translate}\")\n",
    "print(f\"Translated text: {translated_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709c9286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_transcript_translate(transcript, source_language):\n",
    "    '''This processes the extracted subtitle and combines all its texts into one long string.'''\n",
    "    \n",
    "    translator = Translator()\n",
    "    \n",
    "    string = '' #Declares an initial empty string\n",
    "\n",
    "    #Loops through the extracted transcript to compile it for further processing\n",
    "    for subt in transcript:\n",
    "        if subt['text'] != '[Music]':\n",
    "            # Translate the text to English\n",
    "            translated_text = translator.translate(subt['text'], src=source_language, dest='en')\n",
    "            text = (translated_text.text).replace('\\n',' ')\n",
    "            print(text)\n",
    "            string = string+f\" {text}\"\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4448f611",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0af4e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "combined_transl_transcript = combine_transcript_translate(video_transcript, 'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9d5e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_transl_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cafc97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "combined_transcript = combine_transcript(video_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23170d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582d3d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_subts = [(i, video_transcript[i]['text'], 'fr') for i in range(len(video_transcript)) if video_transcript[i]['text'] != '[Music]']\n",
    "    \n",
    "len_of_sublists = int(round(len(list_of_subts)/4))\n",
    "sublist_of_subts = [list_of_subts[i:i+len_of_sublists] for i in range(0, len(list_of_subts), len_of_sublists)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db16c940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#channel_id = \"UC_x5XG1OV2P6uZZ5FSM9Ttw\"\n",
    "#channel_id = \"UCoUWq2QawqdC3-nRXKk-JUw\"\n",
    "channel_id = \"UClEGQZlQURxTiMdwBPqiKDQ\"\n",
    "\n",
    "video_details = get_video_details( channel_id)\n",
    "\n",
    "count = 0\n",
    "for video in video_details:\n",
    "    print(f\"Video Title: {video['snippet']['title']}\")\n",
    "    print(f\"Video ID: {video['snippet']['resourceId']['videoId']}\")\n",
    "    print(f\"Published At: {video['snippet']['publishedAt']}\")\n",
    "    print(\"--------\")\n",
    "    count += 1\n",
    "    \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4d5280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
